{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f648627-2a87-4e94-af89-466348f9417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import tarfile\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8409f8-b48e-4373-9b0a-7813a720328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(chips, i=0):\n",
    "    rgb = chips[i, [3, 2, 1], :, :]\n",
    "    rgb = rgb.transpose(1, 2, 0)\n",
    "    rgb = np.clip(rgb, 0, 2500)\n",
    "    rgb = (rgb / 2500) * 0xff\n",
    "    rgb = rgb.astype(np.uint8)\n",
    "\n",
    "    plt.imshow(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2957d4ff-dc58-494b-b67f-101f6bf75aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_all(chips):\n",
    "    grid_size = int(np.ceil(np.sqrt(chips.shape[0])))\n",
    "    fig, ax = plt.subplots(grid_size, grid_size, figsize=(12, 12))\n",
    "\n",
    "    for i in range(grid_size * grid_size):\n",
    "        if i < chips.shape[0]:\n",
    "            rgb = chips[i, [3, 2, 1], :, :]\n",
    "            rgb = rgb.transpose(1, 2, 0)\n",
    "            rgb = np.clip(rgb, 0, 2500)\n",
    "            rgb = (rgb / 2500) * 0xff\n",
    "            rgb = rgb.astype(np.uint8)\n",
    "            ax[i // grid_size, i % grid_size].imshow(rgb)\n",
    "            ax[i // grid_size, i % grid_size].axis('off')\n",
    "        else:\n",
    "            # Hide empty subplots\n",
    "            ax[i // grid_size, i % grid_size].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305cf56d-cf25-46bb-b938-b8056fe7317a",
   "metadata": {},
   "source": [
    "# Attention #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05aebea9-33db-46bb-a85b-2ced4e29c090",
   "metadata": {},
   "source": [
    "## Load and patch models ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7845cd83-a337-4b1e-a9fc-6dc6c028f227",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8519756b-07ce-488d-bd9a-d80b2678cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_forward(self, x):\n",
    "    (series, channels, height, width) = x.shape\n",
    "    batch = 1\n",
    "    shape = [-1, channels, height, width]\n",
    "    x = x.reshape(*shape)  # (batch * series, channels, height, width)\n",
    "    x = self.net(x).squeeze()  # (batch * series, E)\n",
    "\n",
    "    attn_weights = self.classifier(x)  # (batch * series, D1)\n",
    "    attn_weights = self.attn_linear1(attn_weights)  # (batch * series, D2)\n",
    "    attn_weights = F.relu(attn_weights)\n",
    "    attn_weights = self.attn_linear2(attn_weights)  # (batch * series, 1)\n",
    "    shape = [batch, series, 1]\n",
    "    attn_weights = attn_weights.reshape(*shape)  # (batch, series, 1)\n",
    "    attn_weights = F.softmax(attn_weights, dim=1)\n",
    "\n",
    "    shape = list(x.shape)\n",
    "    shape = [batch, series] + shape[1:]\n",
    "    x = x.reshape(*shape)  # (batch, series, E)\n",
    "    x = x * attn_weights\n",
    "    x = torch.sum(x, dim=1)  # (batch, E)\n",
    "    return x, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5d0c52-1806-467d-b890-20bdac095324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e0a94a-ec0c-4f1f-a83b-2909a811acde",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "for arch in [\"mobilenetv3\", \"resnet18\", \"resnet34\", \"resnet50\"]:\n",
    "    with tarfile.open(f\"/datasets/geospatial-time-series/models/{arch}.tar.gz\", \"r:gz\") as tar:\n",
    "        model = torch.load(tar.extractfile(\"model.pth\"), map_location=device).to(device)\n",
    "    model.forward = types.MethodType(new_forward, model)\n",
    "    model.eval()\n",
    "    models.update({arch: model})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7326fa13-07db-404d-844d-2ff01404b9b7",
   "metadata": {},
   "source": [
    "## Subroutine to display ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b764b5-9b05-4ee0-a7d5-68f402d58ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def display_all_attn(chips, border_colors):\n",
    "    # Normalize the border_colors array\n",
    "    min_color = np.min(border_colors)\n",
    "    max_color = np.max(border_colors)\n",
    "    border_colors = (border_colors - min_color) / (max_color - min_color)\n",
    "    \n",
    "    grid_size = int(np.ceil(np.sqrt(chips.shape[0])))\n",
    "    fig, ax = plt.subplots(grid_size, grid_size, figsize=(12, 12))\n",
    "\n",
    "    for i in range(grid_size * grid_size):\n",
    "        if i < chips.shape[0]:\n",
    "            rgb = chips[i, [3, 2, 1], :, :]\n",
    "            rgb = rgb.transpose(1, 2, 0)\n",
    "            rgb = np.clip(rgb, 0, 2500)\n",
    "            rgb = (rgb / 2500) * 0xff\n",
    "            rgb = rgb.astype(np.uint8)\n",
    "            \n",
    "            ax[i // grid_size, i % grid_size].imshow(rgb)\n",
    "            \n",
    "            # Add colored border based on the normalized border_colors array\n",
    "            border_color = (border_colors[i], 0, 1-border_colors[i]) # (Red, Green, Blue)\n",
    "            rect = patches.Rectangle((0,0), rgb.shape[1], rgb.shape[0], linewidth=13, edgecolor=border_color, facecolor='none')\n",
    "            ax[i // grid_size, i % grid_size].add_patch(rect)\n",
    "            \n",
    "            ax[i // grid_size, i % grid_size].axis('off')\n",
    "        else:\n",
    "            # Hide empty subplots\n",
    "            ax[i // grid_size, i % grid_size].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80759c19-104c-4df3-9caf-b7c2cfb9c5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.gridspec as gridspec\n",
    "import math\n",
    "\n",
    "def png_all_attn(chips, border_colors, filename='attention.png'):\n",
    "    # Normalize the border_colors array\n",
    "    min_color = np.min(border_colors)\n",
    "    max_color = np.max(border_colors)\n",
    "    border_colors = (border_colors - min_color) / (max_color - min_color)\n",
    "\n",
    "    num_chips = chips.shape[0]\n",
    "    \n",
    "    # Calculate grid size to make pictures larger and fill more space\n",
    "    grid_size_y = int(np.ceil(np.sqrt(num_chips)))\n",
    "    grid_size_x = math.ceil(num_chips / grid_size_y)\n",
    "    \n",
    "    fig = plt.figure(figsize=(30, 30), dpi=72)\n",
    "    \n",
    "    # Use GridSpec for more control over subplot sizes\n",
    "    gs = gridspec.GridSpec(grid_size_x, grid_size_y, wspace=0.1, hspace=0.1)\n",
    "\n",
    "    for i in range(num_chips):\n",
    "        row = i // grid_size_y\n",
    "        col = i % grid_size_y\n",
    "\n",
    "        ax = fig.add_subplot(gs[row, col])\n",
    "\n",
    "        rgb = chips[i, [3, 2, 1], :, :]\n",
    "        rgb = rgb.transpose(1, 2, 0)\n",
    "        rgb = np.clip(rgb, 0, 2500)\n",
    "        rgb = (rgb / 2500) * 0xff\n",
    "        rgb = rgb.astype(np.uint8)\n",
    "\n",
    "        ax.imshow(rgb)\n",
    "\n",
    "        # Add colored border based on the normalized border_colors array\n",
    "        border_color = (border_colors[i], 0, 1 - border_colors[i])  # (Red, Green, Blue)\n",
    "        rect = patches.Rectangle((0, 0), rgb.shape[1], rgb.shape[0], linewidth=39, edgecolor=border_color, facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        ax.axis('off')\n",
    "\n",
    "    # Save the figure in 4K resolution with dpi set to 72\n",
    "    plt.savefig(filename, dpi=72)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e553cd8f-b3c1-4c8a-9e8d-fdbbe23b7284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.gridspec as gridspec\n",
    "import math\n",
    "\n",
    "def png_all_attn(chips, border_colors=None, filename='attention.png'):\n",
    "    if border_colors is not None:\n",
    "        # Normalize the border_colors array\n",
    "        min_color = np.min(border_colors)\n",
    "        max_color = np.max(border_colors)\n",
    "        border_colors = (border_colors - min_color) / (max_color - min_color)\n",
    "\n",
    "    num_chips = chips.shape[0]\n",
    "    \n",
    "    # Calculate grid size to make pictures larger and fill more space\n",
    "    grid_size_y = int(np.ceil(np.sqrt(num_chips)))\n",
    "    grid_size_x = math.ceil(num_chips / grid_size_y)\n",
    "    \n",
    "    fig = plt.figure(figsize=(30, 30), dpi=72)\n",
    "    \n",
    "    # Use GridSpec for more control over subplot sizes\n",
    "    gs = gridspec.GridSpec(grid_size_x, grid_size_y, wspace=0.1, hspace=0.1)\n",
    "\n",
    "    for i in range(num_chips):\n",
    "        row = i // grid_size_y\n",
    "        col = i % grid_size_y\n",
    "\n",
    "        ax = fig.add_subplot(gs[row, col])\n",
    "\n",
    "        rgb = chips[i, [3, 2, 1], :, :]\n",
    "        rgb = rgb.transpose(1, 2, 0)\n",
    "        rgb = np.clip(rgb, 0, 2500)\n",
    "        rgb = (rgb / 2500) * 0xff\n",
    "        rgb = rgb.astype(np.uint8)\n",
    "\n",
    "        ax.imshow(rgb)\n",
    "\n",
    "        # If border_colors is provided, use it; otherwise set the border color to black\n",
    "        if border_colors is not None:\n",
    "            border_color = (border_colors[i], 0, 1 - border_colors[i])  # (Red, Green, Blue)\n",
    "        else:\n",
    "            border_color = (0, 0, 0)  # Black\n",
    "\n",
    "        rect = patches.Rectangle((0, 0), rgb.shape[1], rgb.shape[0], linewidth=39, edgecolor=border_color, facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        ax.axis('off')\n",
    "\n",
    "    # Save the figure in 4K resolution with dpi set to 72\n",
    "    plt.savefig(filename, dpi=72)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73b07a4-a4ca-4ee3-8c3a-82e895f9ad56",
   "metadata": {},
   "source": [
    "## Perform inference and display ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4072f4-de35-4073-8603-78db0da792d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chips = np.load(\"/datasets/foss4g-data/orchard/38NMG/1223333130323/chip/ef04cd384ecc47a2b724fe5ebe56843e.chip.npz\").get(\"chips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a0b1e2-1813-4353-a91f-420eb1319a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    e, w = models.get(\"mobilenetv3\")(torch.tensor(chips.astype(np.float32), device=device))\n",
    "e = e.cpu().numpy()[0, :]\n",
    "w = w.cpu().numpy()[0, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25828419-bec1-483c-9dac-48c2ad2869f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_all_attn(chips, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2714d05-48a8-45b5-aa91-9fb1b938c506",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    e, w = models.get(\"resnet50\")(torch.tensor(chips.astype(np.float32), device=device))\n",
    "e = e.cpu().numpy()[0, :]\n",
    "w = w.cpu().numpy()[0, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3269d8-2ab0-495f-b893-093bc9e2d69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_all_attn(chips, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98234cd-a8ee-4a7c-a15a-3af3de9c17fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "png_all_attn(chips, None, \"attended_before.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9129e0-2f12-4754-86cf-75b2a73d4afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "png_all_attn(chips, w, \"attended_after.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f536c29f-d17c-4c7d-905f-470dd7e4e357",
   "metadata": {},
   "source": [
    "convert image1.png image2.png -morph 10 result.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d105e5-e2ff-4eff-a4a1-a4129c7c2065",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
